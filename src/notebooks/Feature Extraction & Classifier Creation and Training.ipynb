{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DEPENDENCIES\n",
    "\n",
    "Fix for Jupyter Notebook imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:\\Dropbox\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\\src\\notebooks\n",
      "\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\python35.zip\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\DLLs\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\cycler-0.10.0-py3.5.egg\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\gmzco\\.ipython\n",
      "S:\\Dropbox\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "# sys.path.append(\"S:\\Dropbox\\\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\")\n",
    "\n",
    "for path in sys.path: print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the additional entry if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\python35.zip\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\DLLs\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\cycler-0.10.0-py3.5.egg\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\gmzco\\.ipython\n",
      "S:\\Dropbox\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\n"
     ]
    }
   ],
   "source": [
    "# sys.path = sys.path[:-1]\n",
    "\n",
    "for path in sys.path: print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.helpers.features' from 'S:\\\\Dropbox\\\\000 - CARND\\\\CarND-T1-P5-Vehicle-Detection\\\\src\\\\helpers\\\\features.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import src.helpers.constants as C\n",
    "import src.helpers.io as IO\n",
    "import src.helpers.features as FT\n",
    "\n",
    "# RELOAD:\n",
    "\n",
    "reload(C)\n",
    "reload(IO)\n",
    "reload(FT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA\n",
    "\n",
    "First, load all images filenames on the datasets, split into cars and non-cars. Print the counts and percentages of each to verify that the dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CAR IMAGES  8792 =  48.73 %\n",
      "NON-CAR IMAGES  9249 =  51.27 %\n",
      "-------------------------------\n",
      "         TOTAL 18041 = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_cars = glob.glob(\"../../input/images/dataset/vehicles/*/*.png\")\n",
    "files_no_cars = glob.glob(\"../../input/images/dataset/non-vehicles/*/*.png\")\n",
    "\n",
    "count_cars = len(files_cars)\n",
    "count_no_cars = len(files_no_cars)\n",
    "count_total = count_cars + count_no_cars\n",
    "\n",
    "percent_cars = 100 * count_cars / count_total\n",
    "percent_no_cars = 100 * count_no_cars / count_total\n",
    "\n",
    "print(\"    CAR IMAGES {0:5d} = {1:6.2f} %\".format(count_cars, percent_cars))\n",
    "print(\"NON-CAR IMAGES {0:5d} = {1:6.2f} %\".format(count_no_cars, percent_no_cars))\n",
    "print(\"-------------------------------\")\n",
    "print(\"         TOTAL {0:5d} = 100.00 %\".format(count_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks quite balanced, so no need to do any augmentation. \n",
    "\n",
    "Next, preload them and check their total size to see if it's feasible to preload them all in different color spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load all images (RGB only):\n",
    "imgs_cars = IO.load_images_rgb(files_cars)\n",
    "imgs_no_cars = IO.load_images_rgb(files_no_cars)\n",
    "\n",
    "# Calculate their size by dumping them:\n",
    "size_cars_b = sys.getsizeof(pickle.dumps(imgs_cars))\n",
    "size_no_cars_b = sys.getsizeof(pickle.dumps(imgs_no_cars))\n",
    "size_total_b = size_cars_b + size_no_cars_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results in multiple units and calculate total for all channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CAR IMAGES SIZE = 108571843.00 B  = 103.54 MB\n",
      "      NON-CAR IMAGES SIZE = 114215338.00 B  = 108.92 MB\n",
      "---------------------------------------------------\n",
      "               TOTAL SIZE = 222787181.00 B  = 212.47 MB\n",
      "ESTIMATED ALL SPACES SIZE =      1699.73 MB =   1.66 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size_cars_mb = size_cars_b / 1048576\n",
    "size_no_cars_mb = size_no_cars_b / 1048576\n",
    "size_total_mb = size_total_b / 1048576\n",
    "size_all_spaces_mb = size_total_mb * (1 + len(C.COLOR_SPACES)) # RGB not included in C.COLOR_SPACES\n",
    "\n",
    "size_all_spaces_gb = size_all_spaces_mb / 1024\n",
    "\n",
    "print(\"          CAR IMAGES SIZE = {0:12.2f} B  = {1:6.2f} MB\".format(size_cars_b, size_cars_mb))\n",
    "print(\"      NON-CAR IMAGES SIZE = {0:12.2f} B  = {1:6.2f} MB\".format(size_no_cars_b, size_no_cars_mb))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"               TOTAL SIZE = {0:12.2f} B  = {1:6.2f} MB\".format(size_total_b, size_total_mb))\n",
    "print(\"ESTIMATED ALL SPACES SIZE = {0:12.2f} MB = {1:6.2f} GB\".format(size_all_spaces_mb, size_all_spaces_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free up space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try: del imgs_cars\n",
    "except NameError: pass # Was not defined\n",
    "    \n",
    "try: del imgs_no_cars\n",
    "except NameError: pass # Was not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all images in all color spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARS:\n",
    "\n",
    "imgs_cars_rgb, \\\n",
    "imgs_cars_hsv, \\\n",
    "imgs_cars_luv, \\\n",
    "imgs_cars_hls, \\\n",
    "imgs_cars_yuv, \\\n",
    "imgs_cars_ycrcb, \\\n",
    "imgs_cars_gray = IO.load_images_all(files_cars)\n",
    "\n",
    "# NON-CARS:\n",
    "\n",
    "imgs_no_cars_rgb, \\\n",
    "imgs_no_cars_hsv, \\\n",
    "imgs_no_cars_luv, \\\n",
    "imgs_no_cars_hls, \\\n",
    "imgs_no_cars_yuv, \\\n",
    "imgs_no_cars_ycrcb, \\\n",
    "imgs_no_cars_gray = IO.load_images_all(files_no_cars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARS:\n",
    "\n",
    "assert len(imgs_cars_rgb) == count_cars\n",
    "assert len(imgs_cars_hsv) == count_cars\n",
    "assert len(imgs_cars_luv) == count_cars\n",
    "assert len(imgs_cars_hls) == count_cars\n",
    "assert len(imgs_cars_yuv) == count_cars\n",
    "assert len(imgs_cars_ycrcb) == count_cars\n",
    "assert len(imgs_cars_gray) == count_cars\n",
    "\n",
    "# NON-CARS:\n",
    "\n",
    "assert len(imgs_no_cars_rgb) == count_no_cars\n",
    "assert len(imgs_no_cars_hsv) == count_no_cars\n",
    "assert len(imgs_no_cars_luv) == count_no_cars\n",
    "assert len(imgs_no_cars_hls) == count_no_cars\n",
    "assert len(imgs_no_cars_yuv) == count_no_cars\n",
    "assert len(imgs_no_cars_ycrcb) == count_no_cars\n",
    "assert len(imgs_no_cars_gray) == count_no_cars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these images look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156 168 163] 33 192\n",
      "[ 78  18 168] 0 192\n",
      "[173  92 139] 37 197\n",
      "[ 78 162  16] 0 184\n",
      "[165 124 126] 36 187\n",
      "[164 122 127] 36 190\n",
      "164 36 190\n"
     ]
    }
   ],
   "source": [
    "print(imgs_cars_rgb[0][0, 0], np.amin(imgs_cars_rgb[0]), np.amax(imgs_cars_rgb[0]))\n",
    "print(imgs_cars_hsv[0][0, 0], np.amin(imgs_cars_hsv[0]), np.amax(imgs_cars_hsv[0]))\n",
    "print(imgs_cars_luv[0][0, 0], np.amin(imgs_cars_luv[0]), np.amax(imgs_cars_luv[0]))\n",
    "print(imgs_cars_hls[0][0, 0], np.amin(imgs_cars_hls[0]), np.amax(imgs_cars_hls[0]))\n",
    "print(imgs_cars_yuv[0][0, 0], np.amin(imgs_cars_yuv[0]), np.amax(imgs_cars_yuv[0]))\n",
    "print(imgs_cars_ycrcb[0][0, 0], np.amin(imgs_cars_ycrcb[0]), np.amax(imgs_cars_ycrcb[0]))\n",
    "print(imgs_cars_gray[0][0, 0], np.amin(imgs_cars_gray[0]), np.amax(imgs_cars_gray[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free up space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARS:\n",
    "\n",
    "try: del imgs_cars_rgb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_hsv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_luv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_hls\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_yuv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_ycrcb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_gray\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "# NON-CARS:\n",
    "\n",
    "try: del imgs_no_cars_rgb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_hsv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_luv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_hls\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_yuv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_ycrcb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_gray\n",
    "except NameError: pass # Was not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION'S CONCERNS, IMPROVEMENTS, TODOS...\n",
    "\n",
    "- Should images that belong to the same sequence be grouped together so that half of each of them can go to a different subset (training and test)?\n",
    "- __Images visualizations in different color spaces.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EXTRACT FEATURES\n",
    "\n",
    "- All with each color schema\n",
    "- Binned + Hist / HOG with each color schema\n",
    "- Ensambles of above (each and multi color schema)\n",
    "- All with color schema combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINNED\n",
      "HIST\n",
      "HOG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Use a subset to train params!\n",
    "\n",
    "# TODO: Add channel to all feature methods or check how I did it in project 4\n",
    "# TOOO: Plot hog and histograms (cars VS non cars)\n",
    "\n",
    "ft_car_binned = FT.extract_binned_color(imgs_cars_hls, size=(8, 8))\n",
    "ft_no_car_binned = FT.extract_binned_color(imgs_no_cars_hls, size=(8, 8))\n",
    "\n",
    "print(\"BINNED\")\n",
    "\n",
    "ft_car_hist = FT.extract_histogram_color(imgs_cars_hls, bins=32)\n",
    "ft_no_car_hist = FT.extract_histogram_color(imgs_no_cars_hls, bins=32)\n",
    "\n",
    "print(\"HIST\")\n",
    "\n",
    "ft_car_hog = FT.extract_hog(imgs_cars_hls, orients=9, ppc=12, cpb=2)\n",
    "ft_no_car_hog = FT.extract_hog(imgs_no_cars_hls, orients=9, ppc=12, cpb=2)\n",
    "\n",
    "print(\"HOG\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3. TRAIN CLASSIFIER (SVM)\n",
    " \n",
    " First, generate the final features vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 2016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_car = FT.combine_features((ft_car_binned, ft_car_hist, ft_car_hog))\n",
    "features_no_car = FT.combine_features((ft_no_car_binned, ft_no_car_hist, ft_no_car_hog))\n",
    "\n",
    "print('Feature vector length:', len(features_car[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, train a classifier with them and check some stats about its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TRAINING TIME = 6.5213 SEC\n",
      "TRAINING ACCURACY = 1.0000 %\n",
      "    TEST ACCURACY = 0.9839 %\n",
      "\n",
      "CONFUSION MATRIX (TRAIN / TEST / ALL):\n",
      "[[7371    0]\n",
      " [   0 7061]]\n",
      "[[1840   38]\n",
      " [  20 1711]]\n",
      "[[9211   38]\n",
      " [  20 8772]]\n",
      "PREDICTION TIME = 1.0324 MS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an array stack of feature vectors and a vector of labels:\n",
    "X = np.vstack((features_car, features_no_car)).astype(np.float64)   \n",
    "y = np.hstack((np.ones(count_cars), np.zeros(count_no_cars)))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# Create a Pipeline to be able to save scaler and classifier together:\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('SCALER',     StandardScaler()),\n",
    "    ('CLASSIFIER', LinearSVC(loss=\"hinge\"))\n",
    "])\n",
    "\n",
    "# Pipeline. See: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "# SVC VS LinearSVC. See: https://stackoverflow.com/questions/35076586/linearsvc-vs-svckernel-linear-conflicting-arguments\n",
    "\n",
    "\n",
    "# Train the model:\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "t = time.time() - t0\n",
    "\n",
    "\n",
    "# Output model's stats:\n",
    "\n",
    "print(\"    TRAINING TIME = {0:2.4f} SEC\".format(t))\n",
    "print(\"TRAINING ACCURACY = {0:2.4f} %\".format(clf.score(X_train, y_train)))\n",
    "print(\"    TEST ACCURACY = {0:2.4f} %\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "print(\"\\nCONFUSION MATRIX (TRAIN / TEST / ALL):\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_pred = clf.predict(X)\n",
    "\n",
    "t = time.time() - t0\n",
    "\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "print(\"PREDICTION TIME = {0:2.4f} MS\".format(t, 1000 * t / (2 * count_total)))\n",
    "\n",
    "\n",
    "# TODO: Automatically adjust classifier's params!\n",
    "\n",
    "# LinearSVC:\n",
    "# 0.9859 with loss=\"hinge\"\n",
    "# 0.9840 with C=100, loss=\"hinge\"\n",
    "# 0.9825 with nothing\n",
    "# 0.9825 with C=10, loss=\"hinge\"\n",
    "# 0.9823 with dual=False\n",
    "# 0.9823 with C=10\n",
    "\n",
    "# SVC kernel=\"linear\": SLOW\n",
    "# 0.9865 with nothing\n",
    "# 0.9862 with C=10\n",
    "# 0.9854 with C=100\n",
    "\n",
    "# SVC kernel=\"rbf\": SUPER SLOW\n",
    "# 0.9913 with nothing\n",
    "# 0.9620 with gamma=0.01\n",
    "\n",
    "# SVC kernel=\"poly\": SLOW\n",
    "# 0.9524 with nothing\n",
    "\n",
    "# DecisionTreeClassifier:\n",
    "# 0.9657 with min_samples_split=10\n",
    "# 0.9631 with max_depth=32\n",
    "# 0.9628 with min_samples_split=32\n",
    "# 0.9626 with min_samples_split=10, max_depth=16\n",
    "# 0.9620 with max_depth=8\n",
    "# 0.9614 with nothing\n",
    "# 0.9614 with min_samples_split=10, max_depth=32\n",
    "# 0.9592 with max_depth=16\n",
    "# 0.9566 with min_samples_split=10, max_depth=8\n",
    "# 0.9544 with criterion=\"entropy\"\n",
    "\n",
    "# GaussianNB:\n",
    "# 0.8229 with nothing\n",
    "\n",
    "# RandomForestClassifier:\n",
    "# 0.9882 with n_estimators=20\n",
    "# 0.9856 with n_estimators=24\n",
    "# 0.9856 with n_estimators=32\n",
    "# 0.9797 with nothing\n",
    "\n",
    "# AdaBoostClassifier: SUPER SLOW\n",
    "# 0.9891 with nothing\n",
    "# 0.9885 with n_estimators=100\n",
    "\n",
    "\n",
    "# ALL ABOVE WITH HSV IMAGES. BELOW, LinearSVC with loss=\"hinge\" in other color spaces:\n",
    "# RGB: 0.9820 - OK (very few false positives). Does not detect black car.\n",
    "# HSV: 0.9859 - Lots of false positives (especially with bigger window). Does not detect black car.\n",
    "# LUV: 0.9896 - Lots of false positives (especially with bigger window). Detects both cars.\n",
    "# HSL: 0.9851 - OK (still problematic with bigger window). Detects both cars.\n",
    "# YUV: 0.9893 - Lots of false positives (especially with bigger window). Detects both cars.\n",
    "# YCRCB: 0.9842 - Lots of false positives (especially with bigger window). Detects both cars.\n",
    "\n",
    "# RGB (binned + hist) + HSL (hog): 0.9814 - Lots of false positives. Does not detect black car.\n",
    "# RGB (hog) + HSL (binned + hist): 0.9859 - Lots of false positives (especially with bigger window) quite ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ANALYZE ERRORS\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../output/models/classifier.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Save each model with the params used?\n",
    "\n",
    "joblib.dump(clf, \"../../output/models/classifier.pkl\")\n",
    "\n",
    "# See: http://scikit-learn.org/stable/modules/model_persistence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
