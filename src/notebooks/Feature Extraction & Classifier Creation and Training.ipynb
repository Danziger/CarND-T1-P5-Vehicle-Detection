{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DEPENDENCIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix for Jupyter Notebook imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:\\Dropbox\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\\src\\notebooks\n",
      "\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\python35.zip\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\DLLs\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\cycler-0.10.0-py3.5.egg\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\gmzco\\.ipython\n",
      "S:\\Dropbox\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "sys.path.append(\"S:\\Dropbox\\\\000 - CARND\\CarND-T1-P5-Vehicle-Detection\")\n",
    "\n",
    "for path in sys.path: print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the additional entry if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\python35.zip\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\DLLs\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\cycler-0.10.0-py3.5.egg\n",
      "C:\\Users\\gmzco\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\gmzco\\.ipython\n"
     ]
    }
   ],
   "source": [
    "sys.path = sys.path[:-1]\n",
    "\n",
    "for path in sys.path: print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.helpers.features' from 'S:\\\\Dropbox\\\\000 - CARND\\\\CarND-T1-P5-Vehicle-Detection\\\\src\\\\helpers\\\\features.py'>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from importlib import reload\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import src.helpers.constants as C\n",
    "import src.helpers.io as IO\n",
    "import src.helpers.features as FT\n",
    "\n",
    "\n",
    "reload(C)\n",
    "reload(IO)\n",
    "reload(FT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA\n",
    "\n",
    "First, load all images filenames on the datasets, split into cars and non-cars. Print the counts and percentages of each to verify that the dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CAR IMAGES  8792 =  49.50 %\n",
      "NON-CAR IMAGES  8968 =  50.50 %\n",
      "-------------------------------\n",
      "         TOTAL 17760 = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files_cars = glob.glob(\"../../input/images/dataset/vehicles/*/*.png\")\n",
    "files_no_cars = glob.glob(\"../../input/images/dataset/non-vehicles/*/*.png\")\n",
    "\n",
    "count_cars = len(files_cars)\n",
    "count_no_cars = len(files_no_cars)\n",
    "count_total = count_cars + count_no_cars\n",
    "\n",
    "percent_cars = 100 * count_cars / count_total\n",
    "percent_no_cars = 100 * count_no_cars / count_total\n",
    "\n",
    "print(\"    CAR IMAGES {0:5d} = {1:6.2f} %\".format(count_cars, percent_cars))\n",
    "print(\"NON-CAR IMAGES {0:5d} = {1:6.2f} %\".format(count_no_cars, percent_no_cars))\n",
    "print(\"-------------------------------\")\n",
    "print(\"         TOTAL {0:5d} = 100.00 %\".format(count_total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks quite balanced, so no need to do any augmentation. \n",
    "\n",
    "Next, preload them and check their total size to see if it's feasible to preload them all in different color spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load all images (RGB only):\n",
    "imgs_cars = IO.load_images_rgb(files_cars)\n",
    "imgs_no_cars = IO.load_images_rgb(files_no_cars)\n",
    "\n",
    "# Calculate their size by dumping them:\n",
    "size_cars_b = sys.getsizeof(pickle.dumps(imgs_cars))\n",
    "size_no_cars_b = sys.getsizeof(pickle.dumps(imgs_no_cars))\n",
    "size_total_b = size_cars_b + size_no_cars_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results in multiple units and calculate total for all channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CAR IMAGES SIZE = 432680131.00 B  = 412.64 MB\n",
      "      NON-CAR IMAGES SIZE = 441341619.00 B  = 420.90 MB\n",
      "---------------------------------------------------\n",
      "               TOTAL SIZE = 874021750.00 B  = 833.53 MB\n",
      "ESTIMATED ALL SPACES SIZE =      5001.19 MB =   4.88 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size_cars_mb = size_cars_b / 1048576\n",
    "size_no_cars_mb = size_no_cars_b / 1048576\n",
    "size_total_mb = size_total_b / 1048576\n",
    "size_all_spaces_mb = size_total_mb * (1 + len(C.COLOR_SPACES)) # RGB not included in C.COLOR_SPACES\n",
    "\n",
    "size_all_spaces_gb = size_all_spaces_mb / 1024\n",
    "\n",
    "print(\"          CAR IMAGES SIZE = {0:12.2f} B  = {1:6.2f} MB\".format(size_cars_b, size_cars_mb))\n",
    "print(\"      NON-CAR IMAGES SIZE = {0:12.2f} B  = {1:6.2f} MB\".format(size_no_cars_b, size_no_cars_mb))\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"               TOTAL SIZE = {0:12.2f} B  = {1:6.2f} MB\".format(size_total_b, size_total_mb))\n",
    "print(\"ESTIMATED ALL SPACES SIZE = {0:12.2f} MB = {1:6.2f} GB\".format(size_all_spaces_mb, size_all_spaces_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free up space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try: del imgs_cars\n",
    "except NameError: pass # Was not defined\n",
    "    \n",
    "try: del imgs_no_cars\n",
    "except NameError: pass # Was not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all images in all color spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARS:\n",
    "\n",
    "imgs_cars_rgb, \\\n",
    "imgs_cars_hsv, \\\n",
    "imgs_cars_luv, \\\n",
    "imgs_cars_hls, \\\n",
    "imgs_cars_yuv, \\\n",
    "imgs_cars_ycrcb, \\\n",
    "imgs_cars_gray = IO.load_images_all(files_cars)\n",
    "\n",
    "# NON-CARS:\n",
    "\n",
    "imgs_no_cars_rgb, \\\n",
    "imgs_no_cars_hsv, \\\n",
    "imgs_no_cars_luv, \\\n",
    "imgs_no_cars_hls, \\\n",
    "imgs_no_cars_yuv, \\\n",
    "imgs_no_cars_ycrcb, \\\n",
    "imgs_no_cars_gray = IO.load_images_all(files_no_cars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARS:\n",
    "\n",
    "assert len(imgs_cars_rgb) == count_cars\n",
    "assert len(imgs_cars_hsv) == count_cars\n",
    "assert len(imgs_cars_luv) == count_cars\n",
    "assert len(imgs_cars_hls) == count_cars\n",
    "assert len(imgs_cars_yuv) == count_cars\n",
    "assert len(imgs_cars_ycrcb) == count_cars\n",
    "assert len(imgs_cars_gray) == count_cars\n",
    "\n",
    "# NON-CARS:\n",
    "\n",
    "assert len(imgs_no_cars_rgb) == count_no_cars\n",
    "assert len(imgs_no_cars_hsv) == count_no_cars\n",
    "assert len(imgs_no_cars_luv) == count_no_cars\n",
    "assert len(imgs_no_cars_hls) == count_no_cars\n",
    "assert len(imgs_no_cars_yuv) == count_no_cars\n",
    "assert len(imgs_no_cars_ycrcb) == count_no_cars\n",
    "assert len(imgs_no_cars_gray) == count_no_cars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free up space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARS:\n",
    "\n",
    "try: del imgs_cars_rgb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_hsv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_luv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_hls\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_yuv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_ycrcb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_cars_gray\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "# NON-CARS:\n",
    "\n",
    "try: del imgs_no_cars_rgb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_hsv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_luv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_hls\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_yuv\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_ycrcb\n",
    "except NameError: pass # Was not defined\n",
    "\n",
    "try: del imgs_no_cars_gray\n",
    "except NameError: pass # Was not defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION'S CONCERNS, IMPROVEMENTS, TODOS...\n",
    "\n",
    "- Should images that belong to the same sequence be grouped together so that half of each of them can go to a different subset (training and test)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 Seconds to extract HOG features...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(2, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1c0f5a69de61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotcar_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;31m# Fit a per-column scaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mX_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;31m# Apply the scaler to X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mscaled_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \"\"\"\n\u001b[0;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m--> 612\u001b[1;33m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    468\u001b[0m                              \u001b[1;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[1;32m--> 470\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(2, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Reduce the sample size because HOG features are slow to compute\n",
    "# The quiz evaluator times out after 13s of CPU time\n",
    "sample_size = 500\n",
    "cars = cars[0:sample_size]\n",
    "notcars = notcars[0:sample_size]\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "colorspace = 'HSV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 2 # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "# ACC = 0.890000 using HSV[0] 9 orientations, 8 ppc, 2 cpb\n",
    "# ACC = 0.845000 using HSV[1] 9 orientations, 8 ppc, 2 cpb\n",
    "# ACC = 0.925000 using HSV[2] 9 orientations, 8 ppc, 2 cpb\n",
    "\n",
    "t=time.time()\n",
    "car_features = extract_features(cars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "notcar_features = extract_features(notcars, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "\n",
    "# Check the score of the SVC\n",
    "\n",
    "print(\"ACC = %f using %s[%s] %d orientations, %d ppc, %d cpb\" % (\n",
    "    round(svc.score(X_test, y_test), 4),\n",
    "    colorspace,\n",
    "    str(hog_channel),\n",
    "    orient,\n",
    "    pix_per_cell,\n",
    "    cell_per_block\n",
    "))\n",
    "\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
